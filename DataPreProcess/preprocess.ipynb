{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint SDATA and DBrief and generate a clean output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DBrief = pd.read_csv('../SampleResultsplus.csv')\n",
    "SData = pd.read_csv('../SDataResultsMore.csv', on_bad_lines='skip')\n",
    "\n",
    "SData.shape[0]\n",
    "DBrief.shape[0]\n",
    "\n",
    "pdFinal = pd.concat([SData,DBrief])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No engine for filetype: 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/io/excel/_base.py:1111\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[0;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1111\u001b[0m     engine \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39;49mget_option(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mio.excel.\u001b[39;49m\u001b[39m{\u001b[39;49;00mext\u001b[39m}\u001b[39;49;00m\u001b[39m.writer\u001b[39;49m\u001b[39m\"\u001b[39;49m, silent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1112\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/_config/config.py:261\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/_config/config.py:135\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_option\u001b[39m(pat: \u001b[39mstr\u001b[39m, silent: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 135\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(pat, silent)\n\u001b[1;32m    137\u001b[0m     \u001b[39m# walk the nested dict\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/_config/config.py:121\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    120\u001b[0m         _warn_if_deprecated(pat)\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such keys(s): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(pat)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keys) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mOptionError\u001b[0m: \"No such keys(s): 'io.excel.csv.writer'\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#DBrief = pd.read_csv('SampleResultsplus.csv')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pdClean \u001b[39m=\u001b[39m pdFinal[[\u001b[39m'\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdisplay_name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpublication_year\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpublication_date\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthorships\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcited_by_count\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mconcepts\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmesh\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mgrants\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreferenced_works_count\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mreferenced_works\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcounts_by_year\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mbest_oa_location.source.display_name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mgenerated_tags\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mauthoring_funding\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mauthoring_funding_grant_id\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mauthoring_maintenance_policies\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_uses\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_ml_approach\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_ml_approach_bool\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_data_limits\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_represents_people\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_collected_from_people\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_biases\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_biases_bool\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_sensitivity\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_sensitivity_bool\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_privacy\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_privacy_bool\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muses_data\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_explanation\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_type\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_team_type\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_labour\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_team_demographic\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_target_demographics\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_language\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_speakers_demographics\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcollection_sources\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollection_infrastructure\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_done\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_explanation\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_type\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_manual\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_team_type\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_team_demograaphic\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_infrastructure\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotation_validation_methods\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> 3\u001b[0m pdClean\u001b[39m.\u001b[39;49mto_excel(\u001b[39m\"\u001b[39;49m\u001b[39mOutputResults.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/core/generic.py:2252\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2241\u001b[0m formatter \u001b[39m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2242\u001b[0m     df,\n\u001b[1;32m   2243\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2250\u001b[0m     inf_rep\u001b[39m=\u001b[39minf_rep,\n\u001b[1;32m   2251\u001b[0m )\n\u001b[0;32m-> 2252\u001b[0m formatter\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m   2253\u001b[0m     excel_writer,\n\u001b[1;32m   2254\u001b[0m     sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[1;32m   2255\u001b[0m     startrow\u001b[39m=\u001b[39;49mstartrow,\n\u001b[1;32m   2256\u001b[0m     startcol\u001b[39m=\u001b[39;49mstartcol,\n\u001b[1;32m   2257\u001b[0m     freeze_panes\u001b[39m=\u001b[39;49mfreeze_panes,\n\u001b[1;32m   2258\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m   2259\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2260\u001b[0m )\n",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/io/formats/excel.py:934\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[1;32m    930\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     \u001b[39m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[1;32m    933\u001b[0m     \u001b[39m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m     writer \u001b[39m=\u001b[39m ExcelWriter(  \u001b[39m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[1;32m    935\u001b[0m         writer, engine\u001b[39m=\u001b[39;49mengine, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m    936\u001b[0m     )\n\u001b[1;32m    937\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/sites/empirical/empiricalEnv/lib/python3.9/site-packages/pandas/io/excel/_base.py:1115\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[0;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             engine \u001b[39m=\u001b[39m get_default_engine(ext, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwriter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1114\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 1115\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo engine for filetype: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[39m# for mypy\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[39massert\u001b[39;00m engine \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: No engine for filetype: 'csv'"
     ]
    }
   ],
   "source": [
    "#DBrief = pd.read_csv('SampleResultsplus.csv')\n",
    "pdClean = pdFinal[['doi','display_name','publication_year','publication_date', 'authorships','cited_by_count','concepts','mesh','grants', 'referenced_works_count','referenced_works', 'counts_by_year','best_oa_location.source.display_name','generated_tags','error','authoring_funding','authoring_funding_grant_id','authoring_maintenance_policies','uses_uses','uses_ml_approach','uses_ml_approach_bool','uses_data_limits','uses_represents_people','uses_collected_from_people','uses_biases','uses_biases_bool','uses_sensitivity','uses_sensitivity_bool','uses_privacy','uses_privacy_bool','uses_data','collection_explanation','collection_type','collection_team_type','collection_labour','collection_team_demographic','collection_target_demographics','collection_language','collection_speakers_demographics', 'collection_sources','collection_infrastructure','annotation_done','annotation_explanation','annotation_type','annotation_manual','annotation_team_type','annotation_team_demograaphic','annotation_infrastructure','annotation_validation_methods']]\n",
    "pdClean.to_excel(\"OutputResults.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Yes, the annotation process involves the use o...\n",
      "2    Yes, the following tools or infrastructures we...\n",
      "3    Yes, the annotation process for the data invol...\n",
      "5    No, the context does not provide information a...\n",
      "7    Yes, the tools or infrastructures used during ...\n",
      "Name: annotation_infrastructure, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Â Get the dataset\n",
    "results = pd.read_csv(\"../SampleResults.csv\")\n",
    "uses = results['uses_uses']\n",
    "collection_explanation = results['collection_explanation']\n",
    "annotation_infra = results['annotation_infrastructure']\n",
    "clean_infra = annotation_infra.dropna()\n",
    "print(clean_infra.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanginer/sites/empirical/empiricalEnv/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/joanginer/sites/empirical/empiricalEnv/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/joanginer/sites/empirical/empiricalEnv/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/joanginer/sites/empirical/empiricalEnv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/joanginer/sites/empirical/empiricalEnv/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(uses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>-1_dataset_recommended_covid19_uses</td>\n",
       "      <td>[dataset, recommended, covid19, uses, food, da...</td>\n",
       "      <td>[The recommended uses of the dataset are: \\n1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0_dataset_recommended_uses_data</td>\n",
       "      <td>[dataset, recommended, uses, data, water, usin...</td>\n",
       "      <td>[The recommended uses of the dataset are: \\n- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1_dataset_recommended_uses_data</td>\n",
       "      <td>[dataset, recommended, uses, data, research, t...</td>\n",
       "      <td>[The recommended uses of the dataset are: \\n1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>2_dataset_recommended_uses_gene</td>\n",
       "      <td>[dataset, recommended, uses, gene, analysis, d...</td>\n",
       "      <td>[The recommended uses of the dataset are: \\n1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                 Name  \\\n",
       "0     -1     20  -1_dataset_recommended_covid19_uses   \n",
       "1      0     88      0_dataset_recommended_uses_data   \n",
       "2      1     55      1_dataset_recommended_uses_data   \n",
       "3      2     49      2_dataset_recommended_uses_gene   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [dataset, recommended, covid19, uses, food, da...   \n",
       "1  [dataset, recommended, uses, data, water, usin...   \n",
       "2  [dataset, recommended, uses, data, research, t...   \n",
       "3  [dataset, recommended, uses, gene, analysis, d...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [The recommended uses of the dataset are: \\n1....  \n",
       "1  [The recommended uses of the dataset are: \\n- ...  \n",
       "2  [The recommended uses of the dataset are: \\n1....  \n",
       "3  [The recommended uses of the dataset are: \\n1....  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('empiricalEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89360b3b506189ff5becbf39c3cb07505defd2429225c75617f794206c0b37e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
